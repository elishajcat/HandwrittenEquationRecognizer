{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Mathematical Symbol (HMS) Recognition \n",
    "Author(s): Toyin Adams\n",
    "\n",
    "Overview:\n",
    "1) Symbol Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading / Pre-processing Handwritten Math Symbol (HMS) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class to format HMSDataset for DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTANT FOR CLASSIFICATION\n",
    "LABEL_MAP = {\n",
    "    'dot': '10',\n",
    "    'minus': '11',\n",
    "    'plus': '12',\n",
    "    'slash': '13',\n",
    "    'div': '14',\n",
    "    'equal': '15',\n",
    "    'times': '16',\n",
    "    'w': '17',\n",
    "    'x': '18',\n",
    "    'y': '19',\n",
    "    'z': '20' \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMSDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.symbol_filenames = os.listdir(root_dir)\n",
    "\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        for symb_filename in self.symbol_filenames:\n",
    "            if symb_filename.endswith('.png'):\n",
    "                self.images.append(os.path.join(root_dir, symb_filename))\n",
    "                self.labels.append(symb_filename.split('-')[0])\n",
    "                    \n",
    "        self.labels = [LABEL_MAP[item] if item in LABEL_MAP else item for item in self.labels]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # Convert label to tensor\n",
    "        label = torch.tensor(int(label))\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for CNN Arcitecture for processing HMSs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)  # Assuming input image size is 64x64\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = nn.functional.relu(self.conv3(x))\n",
    "        x = nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = HMSDataset(root_dir='..\\\\HMS-dataset2\\\\symbols', transform=transform)\n",
    "dataset = HMSDataset(root_dir='../HMS-dataset2/symbols', transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot some samples from the dataset\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))  # Adjust the number of subplots as needed\n",
    "\n",
    "for i in range(5):  # Plot the first 5 samples\n",
    "    idx = random.randint(0, len(dataset) - 1)  # Get a random index\n",
    "    image, label = dataset[idx]\n",
    "    image = np.transpose(image.numpy(), (1, 2, 0))  # Convert image tensor to numpy array and transpose dimensions\n",
    "    axes[i].imshow(image.squeeze(), cmap='gray') \n",
    "    axes[i].set_title(f'Label: {label}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sizes of training and testing datasets\n",
    "train_size = int(0.8 * len(dataset))  # 80% of the dataset for training\n",
    "test_size = len(dataset) - train_size  # Remaining 20% for testing \n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10, Step 0/442, Loss: 3.0525786876678467\n",
      "Epoch 0/10, Step 16/442, Loss: 2.3052077293395996\n",
      "Epoch 0/10, Step 32/442, Loss: 1.0651017427444458\n",
      "Epoch 0/10, Step 48/442, Loss: 1.208058476448059\n",
      "Epoch 0/10, Step 64/442, Loss: 0.9040857553482056\n",
      "Epoch 0/10, Step 80/442, Loss: 0.638433575630188\n",
      "Epoch 0/10, Step 96/442, Loss: 0.6590914130210876\n",
      "Epoch 0/10, Step 112/442, Loss: 0.5885257124900818\n",
      "Epoch 0/10, Step 128/442, Loss: 0.541930615901947\n",
      "Epoch 0/10, Step 144/442, Loss: 0.7124311327934265\n",
      "Epoch 0/10, Step 160/442, Loss: 0.3443608582019806\n",
      "Epoch 0/10, Step 176/442, Loss: 0.5405755043029785\n",
      "Epoch 0/10, Step 192/442, Loss: 0.5141363739967346\n",
      "Epoch 0/10, Step 208/442, Loss: 0.2959391474723816\n",
      "Epoch 0/10, Step 224/442, Loss: 0.11564633250236511\n",
      "Epoch 0/10, Step 240/442, Loss: 0.14182664453983307\n",
      "Epoch 0/10, Step 256/442, Loss: 0.2644442021846771\n",
      "Epoch 0/10, Step 272/442, Loss: 0.412494957447052\n",
      "Epoch 0/10, Step 288/442, Loss: 0.4429701864719391\n",
      "Epoch 0/10, Step 304/442, Loss: 0.43161141872406006\n",
      "Epoch 0/10, Step 320/442, Loss: 0.26542922854423523\n",
      "Epoch 0/10, Step 336/442, Loss: 0.18642368912696838\n",
      "Epoch 0/10, Step 352/442, Loss: 0.3434501588344574\n",
      "Epoch 0/10, Step 368/442, Loss: 0.14697222411632538\n",
      "Epoch 0/10, Step 384/442, Loss: 0.21720337867736816\n",
      "Epoch 0/10, Step 400/442, Loss: 0.07066050171852112\n",
      "Epoch 0/10, Step 416/442, Loss: 0.1389896124601364\n",
      "Epoch 0/10, Step 432/442, Loss: 0.10693825036287308\n",
      "Epoch 1/10, Step 0/442, Loss: 0.22913402318954468\n",
      "Epoch 1/10, Step 16/442, Loss: 0.16557283699512482\n",
      "Epoch 1/10, Step 32/442, Loss: 0.2376161366701126\n",
      "Epoch 1/10, Step 48/442, Loss: 0.08132388442754745\n",
      "Epoch 1/10, Step 64/442, Loss: 0.11900332570075989\n",
      "Epoch 1/10, Step 80/442, Loss: 0.10927128791809082\n",
      "Epoch 1/10, Step 96/442, Loss: 0.18737897276878357\n",
      "Epoch 1/10, Step 112/442, Loss: 0.1696454882621765\n",
      "Epoch 1/10, Step 128/442, Loss: 0.04152056947350502\n",
      "Epoch 1/10, Step 144/442, Loss: 0.16226501762866974\n",
      "Epoch 1/10, Step 160/442, Loss: 0.10737747699022293\n",
      "Epoch 1/10, Step 176/442, Loss: 0.10663709789514542\n",
      "Epoch 1/10, Step 192/442, Loss: 0.16307684779167175\n",
      "Epoch 1/10, Step 208/442, Loss: 0.22582043707370758\n",
      "Epoch 1/10, Step 224/442, Loss: 0.041121482849121094\n",
      "Epoch 1/10, Step 240/442, Loss: 0.09928944706916809\n",
      "Epoch 1/10, Step 256/442, Loss: 0.16517412662506104\n",
      "Epoch 1/10, Step 272/442, Loss: 0.06376859545707703\n",
      "Epoch 1/10, Step 288/442, Loss: 0.09146638214588165\n",
      "Epoch 1/10, Step 304/442, Loss: 0.19734400510787964\n",
      "Epoch 1/10, Step 320/442, Loss: 0.23319575190544128\n",
      "Epoch 1/10, Step 336/442, Loss: 0.09234209358692169\n",
      "Epoch 1/10, Step 352/442, Loss: 0.10818833857774734\n",
      "Epoch 1/10, Step 368/442, Loss: 0.07244173437356949\n",
      "Epoch 1/10, Step 384/442, Loss: 0.15325352549552917\n",
      "Epoch 1/10, Step 400/442, Loss: 0.09774326533079147\n",
      "Epoch 1/10, Step 416/442, Loss: 0.05618482828140259\n",
      "Epoch 1/10, Step 432/442, Loss: 0.0215046014636755\n",
      "Epoch 2/10, Step 0/442, Loss: 0.03616267070174217\n",
      "Epoch 2/10, Step 16/442, Loss: 0.08557821810245514\n",
      "Epoch 2/10, Step 32/442, Loss: 0.0515255369246006\n",
      "Epoch 2/10, Step 48/442, Loss: 0.07901531457901001\n",
      "Epoch 2/10, Step 64/442, Loss: 0.026851871982216835\n",
      "Epoch 2/10, Step 80/442, Loss: 0.05450616031885147\n",
      "Epoch 2/10, Step 96/442, Loss: 0.015260896645486355\n",
      "Epoch 2/10, Step 112/442, Loss: 0.03821268677711487\n",
      "Epoch 2/10, Step 128/442, Loss: 0.014161886647343636\n",
      "Epoch 2/10, Step 144/442, Loss: 0.060841117054224014\n",
      "Epoch 2/10, Step 160/442, Loss: 0.0312972217798233\n",
      "Epoch 2/10, Step 176/442, Loss: 0.04814468324184418\n",
      "Epoch 2/10, Step 192/442, Loss: 0.18742451071739197\n",
      "Epoch 2/10, Step 208/442, Loss: 0.10542414337396622\n",
      "Epoch 2/10, Step 224/442, Loss: 0.0872679129242897\n",
      "Epoch 2/10, Step 240/442, Loss: 0.1971394270658493\n",
      "Epoch 2/10, Step 256/442, Loss: 0.06481374800205231\n",
      "Epoch 2/10, Step 272/442, Loss: 0.07732530683279037\n",
      "Epoch 2/10, Step 288/442, Loss: 0.013877005316317081\n",
      "Epoch 2/10, Step 304/442, Loss: 0.022006617859005928\n",
      "Epoch 2/10, Step 320/442, Loss: 0.04291336238384247\n",
      "Epoch 2/10, Step 336/442, Loss: 0.014846659265458584\n",
      "Epoch 2/10, Step 352/442, Loss: 0.09992758929729462\n",
      "Epoch 2/10, Step 368/442, Loss: 0.07023011893033981\n",
      "Epoch 2/10, Step 384/442, Loss: 0.09307338297367096\n",
      "Epoch 2/10, Step 400/442, Loss: 0.021913805976510048\n",
      "Epoch 2/10, Step 416/442, Loss: 0.013613412156701088\n",
      "Epoch 2/10, Step 432/442, Loss: 0.09760140627622604\n",
      "Epoch 3/10, Step 0/442, Loss: 0.08499181270599365\n",
      "Epoch 3/10, Step 16/442, Loss: 0.038811955600976944\n",
      "Epoch 3/10, Step 32/442, Loss: 0.011153178289532661\n",
      "Epoch 3/10, Step 48/442, Loss: 0.005434179212898016\n",
      "Epoch 3/10, Step 64/442, Loss: 0.07072368264198303\n",
      "Epoch 3/10, Step 80/442, Loss: 0.0025464240461587906\n",
      "Epoch 3/10, Step 96/442, Loss: 0.10122665017843246\n",
      "Epoch 3/10, Step 112/442, Loss: 0.06764742732048035\n",
      "Epoch 3/10, Step 128/442, Loss: 0.010451545007526875\n",
      "Epoch 3/10, Step 144/442, Loss: 0.11082305759191513\n",
      "Epoch 3/10, Step 160/442, Loss: 0.012271886691451073\n",
      "Epoch 3/10, Step 176/442, Loss: 0.09929951280355453\n",
      "Epoch 3/10, Step 192/442, Loss: 0.1528555154800415\n",
      "Epoch 3/10, Step 208/442, Loss: 0.03216337412595749\n",
      "Epoch 3/10, Step 224/442, Loss: 0.016655754297971725\n",
      "Epoch 3/10, Step 240/442, Loss: 0.041054777801036835\n",
      "Epoch 3/10, Step 256/442, Loss: 0.04524261876940727\n",
      "Epoch 3/10, Step 272/442, Loss: 0.03786764666438103\n",
      "Epoch 3/10, Step 288/442, Loss: 0.00741057563573122\n",
      "Epoch 3/10, Step 304/442, Loss: 0.028832778334617615\n",
      "Epoch 3/10, Step 320/442, Loss: 0.006677239201962948\n",
      "Epoch 3/10, Step 336/442, Loss: 0.009829232469201088\n",
      "Epoch 3/10, Step 352/442, Loss: 0.05681392922997475\n",
      "Epoch 3/10, Step 368/442, Loss: 0.07310093194246292\n",
      "Epoch 3/10, Step 384/442, Loss: 0.07760463654994965\n",
      "Epoch 3/10, Step 400/442, Loss: 0.020718812942504883\n",
      "Epoch 3/10, Step 416/442, Loss: 0.08801651000976562\n",
      "Epoch 3/10, Step 432/442, Loss: 0.07999029755592346\n",
      "Epoch 4/10, Step 0/442, Loss: 0.09643532335758209\n",
      "Epoch 4/10, Step 16/442, Loss: 0.0867917537689209\n",
      "Epoch 4/10, Step 32/442, Loss: 0.0045583900064229965\n",
      "Epoch 4/10, Step 48/442, Loss: 0.010693607851862907\n",
      "Epoch 4/10, Step 64/442, Loss: 0.008697668090462685\n",
      "Epoch 4/10, Step 80/442, Loss: 0.0435517355799675\n",
      "Epoch 4/10, Step 96/442, Loss: 0.005919028539210558\n",
      "Epoch 4/10, Step 112/442, Loss: 0.12383399903774261\n",
      "Epoch 4/10, Step 128/442, Loss: 0.03716157004237175\n",
      "Epoch 4/10, Step 144/442, Loss: 0.014161607250571251\n",
      "Epoch 4/10, Step 160/442, Loss: 0.013884900137782097\n",
      "Epoch 4/10, Step 176/442, Loss: 0.06970258057117462\n",
      "Epoch 4/10, Step 192/442, Loss: 0.002641345141455531\n",
      "Epoch 4/10, Step 208/442, Loss: 0.03819090127944946\n",
      "Epoch 4/10, Step 224/442, Loss: 0.025549888610839844\n",
      "Epoch 4/10, Step 240/442, Loss: 0.023745397105813026\n",
      "Epoch 4/10, Step 256/442, Loss: 0.04974814131855965\n",
      "Epoch 4/10, Step 272/442, Loss: 0.07938741892576218\n",
      "Epoch 4/10, Step 288/442, Loss: 0.017622221261262894\n",
      "Epoch 4/10, Step 304/442, Loss: 0.10175108909606934\n",
      "Epoch 4/10, Step 320/442, Loss: 0.017322426661849022\n",
      "Epoch 4/10, Step 336/442, Loss: 0.016512053087353706\n",
      "Epoch 4/10, Step 352/442, Loss: 0.022686680778861046\n",
      "Epoch 4/10, Step 368/442, Loss: 0.06571482867002487\n",
      "Epoch 4/10, Step 384/442, Loss: 0.03371879830956459\n",
      "Epoch 4/10, Step 400/442, Loss: 0.012148480862379074\n",
      "Epoch 4/10, Step 416/442, Loss: 0.02617168426513672\n",
      "Epoch 4/10, Step 432/442, Loss: 0.0045625194907188416\n",
      "Epoch 5/10, Step 0/442, Loss: 0.00627521425485611\n",
      "Epoch 5/10, Step 16/442, Loss: 0.07952824980020523\n",
      "Epoch 5/10, Step 32/442, Loss: 0.00994543731212616\n",
      "Epoch 5/10, Step 48/442, Loss: 0.08849425613880157\n",
      "Epoch 5/10, Step 64/442, Loss: 0.04918377846479416\n",
      "Epoch 5/10, Step 80/442, Loss: 0.043061964213848114\n",
      "Epoch 5/10, Step 96/442, Loss: 0.06841397285461426\n",
      "Epoch 5/10, Step 112/442, Loss: 0.07728248834609985\n",
      "Epoch 5/10, Step 128/442, Loss: 0.0012134619755670428\n",
      "Epoch 5/10, Step 144/442, Loss: 0.015824036672711372\n",
      "Epoch 5/10, Step 160/442, Loss: 0.028765207156538963\n",
      "Epoch 5/10, Step 176/442, Loss: 0.005130893085151911\n",
      "Epoch 5/10, Step 192/442, Loss: 0.00937887467443943\n",
      "Epoch 5/10, Step 208/442, Loss: 0.0063498616218566895\n",
      "Epoch 5/10, Step 224/442, Loss: 0.055356524884700775\n",
      "Epoch 5/10, Step 240/442, Loss: 0.03704673796892166\n",
      "Epoch 5/10, Step 256/442, Loss: 0.051722846925258636\n",
      "Epoch 5/10, Step 272/442, Loss: 0.04773290455341339\n",
      "Epoch 5/10, Step 288/442, Loss: 0.00810734461992979\n",
      "Epoch 5/10, Step 304/442, Loss: 0.03038904070854187\n",
      "Epoch 5/10, Step 320/442, Loss: 0.0055030155926942825\n",
      "Epoch 5/10, Step 336/442, Loss: 0.03839321807026863\n",
      "Epoch 5/10, Step 352/442, Loss: 0.02727619744837284\n",
      "Epoch 5/10, Step 368/442, Loss: 0.002073032781481743\n",
      "Epoch 5/10, Step 384/442, Loss: 0.009029426611959934\n",
      "Epoch 5/10, Step 400/442, Loss: 0.06437817215919495\n",
      "Epoch 5/10, Step 416/442, Loss: 0.028041988611221313\n",
      "Epoch 5/10, Step 432/442, Loss: 0.018341412767767906\n",
      "Epoch 6/10, Step 0/442, Loss: 0.033877115696668625\n",
      "Epoch 6/10, Step 16/442, Loss: 0.05568844452500343\n",
      "Epoch 6/10, Step 32/442, Loss: 0.009845859371125698\n",
      "Epoch 6/10, Step 48/442, Loss: 0.0028907437808811665\n",
      "Epoch 6/10, Step 64/442, Loss: 0.03555456921458244\n",
      "Epoch 6/10, Step 80/442, Loss: 0.10748842358589172\n",
      "Epoch 6/10, Step 96/442, Loss: 0.003442233195528388\n",
      "Epoch 6/10, Step 112/442, Loss: 0.06432194262742996\n",
      "Epoch 6/10, Step 128/442, Loss: 0.020766163244843483\n",
      "Epoch 6/10, Step 144/442, Loss: 0.053474441170692444\n",
      "Epoch 6/10, Step 160/442, Loss: 0.05439316853880882\n",
      "Epoch 6/10, Step 176/442, Loss: 0.02368282899260521\n",
      "Epoch 6/10, Step 192/442, Loss: 0.01163382176309824\n",
      "Epoch 6/10, Step 208/442, Loss: 0.08006086945533752\n",
      "Epoch 6/10, Step 224/442, Loss: 0.009604750201106071\n",
      "Epoch 6/10, Step 240/442, Loss: 0.0015185377560555935\n",
      "Epoch 6/10, Step 256/442, Loss: 0.009932922199368477\n",
      "Epoch 6/10, Step 272/442, Loss: 0.0051204427145421505\n",
      "Epoch 6/10, Step 288/442, Loss: 0.012229115702211857\n",
      "Epoch 6/10, Step 304/442, Loss: 0.04010919854044914\n",
      "Epoch 6/10, Step 320/442, Loss: 0.070205457508564\n",
      "Epoch 6/10, Step 336/442, Loss: 0.10096297413110733\n",
      "Epoch 6/10, Step 352/442, Loss: 0.05114489421248436\n",
      "Epoch 6/10, Step 368/442, Loss: 0.07980258017778397\n",
      "Epoch 6/10, Step 384/442, Loss: 0.029813235625624657\n",
      "Epoch 6/10, Step 400/442, Loss: 0.006922539323568344\n",
      "Epoch 6/10, Step 416/442, Loss: 0.005562761798501015\n",
      "Epoch 6/10, Step 432/442, Loss: 0.005192942917346954\n",
      "Epoch 7/10, Step 0/442, Loss: 0.0007709989440627396\n",
      "Epoch 7/10, Step 16/442, Loss: 0.023942800238728523\n",
      "Epoch 7/10, Step 32/442, Loss: 0.008780871517956257\n",
      "Epoch 7/10, Step 48/442, Loss: 0.022433044388890266\n",
      "Epoch 7/10, Step 64/442, Loss: 0.06560374051332474\n",
      "Epoch 7/10, Step 80/442, Loss: 0.0012018245179206133\n",
      "Epoch 7/10, Step 96/442, Loss: 0.002313819248229265\n",
      "Epoch 7/10, Step 112/442, Loss: 0.020086441189050674\n",
      "Epoch 7/10, Step 128/442, Loss: 0.04639113321900368\n",
      "Epoch 7/10, Step 144/442, Loss: 0.043502405285835266\n",
      "Epoch 7/10, Step 160/442, Loss: 0.009039849042892456\n",
      "Epoch 7/10, Step 176/442, Loss: 0.13556553423404694\n",
      "Epoch 7/10, Step 192/442, Loss: 0.012710546143352985\n",
      "Epoch 7/10, Step 208/442, Loss: 0.0014768894761800766\n",
      "Epoch 7/10, Step 224/442, Loss: 0.00094883848214522\n",
      "Epoch 7/10, Step 240/442, Loss: 0.0725589320063591\n",
      "Epoch 7/10, Step 256/442, Loss: 0.0108998604118824\n",
      "Epoch 7/10, Step 272/442, Loss: 0.012248904444277287\n",
      "Epoch 7/10, Step 288/442, Loss: 0.06439244002103806\n",
      "Epoch 7/10, Step 304/442, Loss: 0.005690889898687601\n",
      "Epoch 7/10, Step 320/442, Loss: 0.0006386494496837258\n",
      "Epoch 7/10, Step 336/442, Loss: 0.0033541030716151\n",
      "Epoch 7/10, Step 352/442, Loss: 0.012831130065023899\n",
      "Epoch 7/10, Step 368/442, Loss: 4.7162873670458794e-05\n",
      "Epoch 7/10, Step 384/442, Loss: 0.08583962172269821\n",
      "Epoch 7/10, Step 400/442, Loss: 0.0035830812994390726\n",
      "Epoch 7/10, Step 416/442, Loss: 0.010774165391921997\n",
      "Epoch 7/10, Step 432/442, Loss: 0.007878052070736885\n",
      "Epoch 8/10, Step 0/442, Loss: 0.048112086951732635\n",
      "Epoch 8/10, Step 16/442, Loss: 0.010049406439065933\n",
      "Epoch 8/10, Step 32/442, Loss: 0.0037512797862291336\n",
      "Epoch 8/10, Step 48/442, Loss: 0.01594613865017891\n",
      "Epoch 8/10, Step 64/442, Loss: 0.004254706669598818\n",
      "Epoch 8/10, Step 80/442, Loss: 0.01047077402472496\n",
      "Epoch 8/10, Step 96/442, Loss: 0.035603102296590805\n",
      "Epoch 8/10, Step 112/442, Loss: 0.010599903762340546\n",
      "Epoch 8/10, Step 128/442, Loss: 0.0032515183556824923\n",
      "Epoch 8/10, Step 144/442, Loss: 0.008416899479925632\n",
      "Epoch 8/10, Step 160/442, Loss: 0.0019627101719379425\n",
      "Epoch 8/10, Step 176/442, Loss: 0.0017892876639962196\n",
      "Epoch 8/10, Step 192/442, Loss: 0.011559488251805305\n",
      "Epoch 8/10, Step 208/442, Loss: 0.005531918723136187\n",
      "Epoch 8/10, Step 224/442, Loss: 0.014613466337323189\n",
      "Epoch 8/10, Step 240/442, Loss: 0.014259299263358116\n",
      "Epoch 8/10, Step 256/442, Loss: 0.0011207052739337087\n",
      "Epoch 8/10, Step 272/442, Loss: 0.0015811139019206166\n",
      "Epoch 8/10, Step 288/442, Loss: 0.000852117664180696\n",
      "Epoch 8/10, Step 304/442, Loss: 0.027884475886821747\n",
      "Epoch 8/10, Step 320/442, Loss: 0.06648293882608414\n",
      "Epoch 8/10, Step 336/442, Loss: 0.006263808347284794\n",
      "Epoch 8/10, Step 352/442, Loss: 0.00243656849488616\n",
      "Epoch 8/10, Step 368/442, Loss: 0.08727625757455826\n",
      "Epoch 8/10, Step 384/442, Loss: 0.013219904154539108\n",
      "Epoch 8/10, Step 400/442, Loss: 0.010271580889821053\n",
      "Epoch 8/10, Step 416/442, Loss: 0.015102764591574669\n",
      "Epoch 8/10, Step 432/442, Loss: 0.0261685810983181\n",
      "Epoch 9/10, Step 0/442, Loss: 0.0006238394416868687\n",
      "Epoch 9/10, Step 16/442, Loss: 0.0016119425417855382\n",
      "Epoch 9/10, Step 32/442, Loss: 0.0010470958659425378\n",
      "Epoch 9/10, Step 48/442, Loss: 0.008188378065824509\n",
      "Epoch 9/10, Step 64/442, Loss: 0.0014422701206058264\n",
      "Epoch 9/10, Step 80/442, Loss: 0.0026044300757348537\n",
      "Epoch 9/10, Step 96/442, Loss: 0.0028999203350394964\n",
      "Epoch 9/10, Step 112/442, Loss: 0.0010845644865185022\n",
      "Epoch 9/10, Step 128/442, Loss: 0.004665606189519167\n",
      "Epoch 9/10, Step 144/442, Loss: 0.05343535169959068\n",
      "Epoch 9/10, Step 160/442, Loss: 0.0008274600841104984\n",
      "Epoch 9/10, Step 176/442, Loss: 0.0001392459380440414\n",
      "Epoch 9/10, Step 192/442, Loss: 0.0007350682863034308\n",
      "Epoch 9/10, Step 208/442, Loss: 0.00024582535843364894\n",
      "Epoch 9/10, Step 224/442, Loss: 0.003630319144576788\n",
      "Epoch 9/10, Step 240/442, Loss: 0.0007366223726421595\n",
      "Epoch 9/10, Step 256/442, Loss: 0.001880956580862403\n",
      "Epoch 9/10, Step 272/442, Loss: 0.023488981649279594\n",
      "Epoch 9/10, Step 288/442, Loss: 0.003968995530158281\n",
      "Epoch 9/10, Step 304/442, Loss: 0.0017534010112285614\n",
      "Epoch 9/10, Step 320/442, Loss: 0.012549894861876965\n",
      "Epoch 9/10, Step 336/442, Loss: 0.0015044405590742826\n",
      "Epoch 9/10, Step 352/442, Loss: 0.0012598299654200673\n",
      "Epoch 9/10, Step 368/442, Loss: 0.0015078478027135134\n",
      "Epoch 9/10, Step 384/442, Loss: 0.00024513303651474416\n",
      "Epoch 9/10, Step 400/442, Loss: 0.0012937006540596485\n",
      "Epoch 9/10, Step 416/442, Loss: 7.952938904054463e-05\n",
      "Epoch 9/10, Step 432/442, Loss: 0.000262695160927251\n",
      "Accuracy on test set: 97.02802151146335%\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = CNN(num_classes=21)  # Change num_classes to the number of classes in your dataset\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 16 == 0:\n",
    "            print(f'Epoch {epoch}/{num_epochs}, Step {batch_idx}/{len(train_loader)}, Loss: {loss.item()}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, targets in test_loader:\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "    print(f'Accuracy on test set: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'math_symbol_classifier_v2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: div\n"
     ]
    }
   ],
   "source": [
    "# Load the image\n",
    "image_path = 'drawn_image.png'\n",
    "image = Image.open(image_path).convert('L')\n",
    "\n",
    "# Preprocess the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize the image to match the input size expected by the model\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize the image\n",
    "])\n",
    "image = transform(image)\n",
    "\n",
    "# Add a batch dimension\n",
    "image = image.unsqueeze(0)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "\n",
    "# Get predicted label\n",
    "_, predicted = torch.max(output, 1)\n",
    "\n",
    "# Convert predicted label tensor to integer\n",
    "predicted_label = predicted.item()\n",
    "\n",
    "idx_map = {int(idx): lbl for lbl, idx in LABEL_MAP.items()}\n",
    "# Map the predicted label to the corresponding class\n",
    "if predicted_label < 10:\n",
    "    predicted_class = predicted_label\n",
    "else:\n",
    "    predicted_class = idx_map[predicted_label]\n",
    "\n",
    "print(\"Predicted Class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: minus\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Load the trained model\n",
    "model = CNN(num_classes=14)  # Assuming the same model architecture as in the training code\n",
    "model.load_state_dict(torch.load('math_symbol_classifier.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Load the image\n",
    "image_path = '12.jpg'\n",
    "image = Image.open(image_path).convert('L')\n",
    "\n",
    "# Preprocess the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize the image to match the input size expected by the model\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize the image\n",
    "])\n",
    "image = transform(image)\n",
    "\n",
    "# Add a batch dimension\n",
    "image = image.unsqueeze(0)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "\n",
    "# Get predicted label\n",
    "_, predicted = torch.max(output, 1)\n",
    "\n",
    "# Convert predicted label tensor to integer\n",
    "predicted_label = predicted.item()\n",
    "\n",
    "# Map the predicted label to the corresponding class\n",
    "idx_map = {int(idx): lbl for lbl, idx in LABEL_MAP.items()}\n",
    "predicted_class = idx_map[predicted_label]\n",
    "\n",
    "print(\"Predicted Class:\", predicted_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
